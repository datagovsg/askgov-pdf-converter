{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tika import parser\n",
    "import re\n",
    "import pprint\n",
    "#Question Asked\tAnswer Given\tTop Match\tAnswer Taught\tCategory\tQuestion Type\tDate Received\tÂ Date Responded\tResponse Time\tProcessed By\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "\n",
    "def get_content(fp):\n",
    "    raw = parser.from_file(fp)\n",
    "\n",
    "    stopwords = set(['\\n', '\\xa0', '\\ue010', '\\ue011'])\n",
    "    content = raw['content'].strip()\n",
    "    content = content.split('\\n')\n",
    "    content = [c.replace(u'\\xa0', u' ') for c in content]\n",
    "    content = [c for c in content if c != '']\n",
    "    content = [x for x in content if x not in stopwords]\n",
    "    \n",
    "    return content\n",
    "    \n",
    "def get_question(content):\n",
    "    found = False\n",
    "    question = []\n",
    "    for i in range(len(content)):\n",
    "        if not found:\n",
    "            search_groups = re.search('^Q (.*)', content[i])\n",
    "            if search_groups is not None:\n",
    "                found = True\n",
    "                qn = search_groups.group(1).strip()\n",
    "                question.append(qn)\n",
    "        else:\n",
    "            if re.match('^A(?!.)|^A (.*)', content[i]):\n",
    "                return ' '.join(question), i\n",
    "                continue\n",
    "            else:\n",
    "                question.append(content[i])\n",
    "    return None, 0\n",
    "\n",
    "def get_answer(content):\n",
    "    found = False\n",
    "    answer = []\n",
    "    for i in range(len(content)):\n",
    "        if not found:\n",
    "            search_groups = re.search('^A(.*)', content[i])\n",
    "            if search_groups is not None:\n",
    "                found = True\n",
    "                ans = search_groups.group(1).strip()\n",
    "                answer.append(ans)\n",
    "        else:\n",
    "            if re.match('^Answer', content[i]):\n",
    "                return ' '.join(answer), i\n",
    "                continue\n",
    "            else:\n",
    "                answer.append(content[i])\n",
    "    return None, 0\n",
    "\n",
    "def get_answer_name(content):\n",
    "    found = False\n",
    "    answer = []\n",
    "    for i in range(len(content)):\n",
    "        if not found:\n",
    "            search_groups = re.search('^Answer Name (.*)', content[i])\n",
    "            if search_groups is not None:\n",
    "                found = True\n",
    "                ans = search_groups.group(1).strip()\n",
    "                answer.append(ans)\n",
    "        else:\n",
    "            if re.match('^Contextual', content[i]):\n",
    "                return ' '.join(answer), i\n",
    "                continue\n",
    "            else:\n",
    "                answer.append(content[i])\n",
    "    return None, 0\n",
    "\n",
    "_fields = { \n",
    "          'answer': 'DEFAULT_ANSWER',\n",
    "          'answer_name': 'DEFAULT_ANSWER_NAME',\n",
    "          'category': 'DEFAULT_CATEGORY',\n",
    "          'created_by': 'DEFAULT_CREATED_BY',\n",
    "          'created_date': 'DEFAULT_CREATED_DATE',\n",
    "          'edited_by': 'DEFAULT_EDITED_BY',\n",
    "          'edited_date': 'DEFAULT_EDITED_DATE',\n",
    "          'question': 'DEFAULT_QUESTION'\n",
    "          }\n",
    "\n",
    "def get_meta(fp):\n",
    "    content = get_content(fp)\n",
    "    _fields['question'], i = get_question(content)\n",
    "    _fields['answer'], i = get_answer(content[i:])\n",
    "    _fields['answer_name'], i = get_answer_name(content[i:])\n",
    "    return _fields\n",
    "\n",
    "def get_phrases(fp):\n",
    "    content = get_content(fp)\n",
    "    # Retrieving training phrases\n",
    "#     indices = [i for i, item in enumerate(content) if re.match('^([0-9]+)(.*)([0-9]+)$', item)]\n",
    "#     if len(indices) > 0:\n",
    "#         start_index = indices[0]\n",
    "#         end_index = indices[-1]\n",
    "#     else:\n",
    "#         return []\n",
    "\n",
    "    indices = [i for i, item in enumerate(content) if re.match('(Question Text Count Reteach)|(flexAnswer Professional v8.8)', item)]\n",
    "    try:\n",
    "        start_index = indices[0] + 1\n",
    "        end_index= indices[1]\n",
    "    except Exception:\n",
    "        return []\n",
    "#     try:\n",
    "#         start_index = content.index('Question Text Count Reteach') + 1\n",
    "#         end_index = content.index('flexAnswer Professional v8.8 ')\n",
    "#     except Exception:\n",
    "#         start_index = content.index('Question Text Count Reteach') + 1\n",
    "#         end_index = content.index('flexAnswer Professional v8.8')\n",
    "    phrases = content[start_index:end_index]\n",
    "    new_phrases = []\n",
    "    for phrase in phrases:\n",
    "        group_1 = re.search('^[0-9]+(.*)[0-9]+$', phrase)\n",
    "        group_2 = re.search('^[0-9]+(.*)[0-9]*$', phrase)\n",
    "        if group_1 is not None:\n",
    "            phr = group_1.group(1).strip()\n",
    "            new_phrases.append(phr)\n",
    "        elif group_2 is not None:\n",
    "            phr = group_2.group(1).strip()\n",
    "            new_phrases.append(phr)\n",
    "        else:\n",
    "            if len(new_phrases) > 0:\n",
    "                new_phrases[-1] += phrase\n",
    "            else:\n",
    "                new_phrases.append(phrase)\n",
    "    new_phrases = [c for c in new_phrases if c != '']\n",
    "    return new_phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start here if you're implementing your own scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-fd7decee5816>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'fp' is not defined"
     ]
    }
   ],
   "source": [
    "get_content(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# For removing duplicatess\n",
    "df = pd.read_csv('datasets/askjaime3months.csv')\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\n",
    "qn_asked =  set(df.question_asked)\n",
    "qn_asked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import natsort\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pdf_folders = natsort.natsorted(os.listdir('pdfs'))\n",
    "pdf_files = dict()\n",
    "for folder in pdf_folders:\n",
    "    files = os.listdir('pdfs'+os.path.sep+folder)\n",
    "    files = natsort.natsorted(files)\n",
    "    pdf_files[folder] = files\n",
    "\n",
    "phrases_df = pd.DataFrame()\n",
    "phrases_count = dict()\n",
    "intents = set()\n",
    "intents_df = pd.DataFrame()\n",
    "\n",
    "PHRASE_CHAR_LIMIT = 768\n",
    "PHRASE_COUNT_LIMIT = 2000\n",
    "\n",
    "for folder in pdf_files.keys():\n",
    "    for file in pdf_files[folder]:\n",
    "        fp = 'pdfs'+os.path.sep+folder+os.path.sep+file\n",
    "        search_groups = re.search('(Q[0-9]*)(-([0-9]*))*\\.pdf', file)\n",
    "        if search_groups is not None:\n",
    "            q_no = search_groups.group(1)\n",
    "        if q_no not in phrases_count:\n",
    "            phrases_count[q_no] = 0\n",
    "        if q_no not in intents:\n",
    "            intents.add(q_no)\n",
    "            meta = get_meta(fp)\n",
    "#             intents_df = intents_df.append({'intent': q_no, 'response': meta['answer']}, ignore_index=True)\n",
    "            intents_df = intents_df.append({'intent': q_no, 'response': meta['answer_name']}, ignore_index=True)\n",
    "        phrases = get_phrases(fp)\n",
    "        for phrase in phrases:\n",
    "            if phrases_count[q_no] < PHRASE_COUNT_LIMIT:\n",
    "                if phrase not in qn_asked:\n",
    "                    phrases_df = phrases_df.append({'intent': q_no, 'phrase': phrase[:PHRASE_CHAR_LIMIT]}, ignore_index=True)\n",
    "                    phrases_count[q_no] += 1\n",
    "            else:\n",
    "                break\n",
    "\n",
    "print('Intents:', len(intents_df), 'Phrases:', len(phrases_df))\n",
    "intents_df.drop_duplicates(keep=False,inplace=True) \n",
    "phrases_df.drop_duplicates(keep=False,inplace=True)\n",
    "\n",
    "print('Intents:', len(intents_df), 'Phrases:', len(phrases_df))\n",
    "intents_df.to_csv('intents.csv', index=False)\n",
    "phrases_df.to_csv('phrases.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
